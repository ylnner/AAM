{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DecissionTreeC45 as c45\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_value(x,y):\n",
    "    if y == 0:\n",
    "        return 0\n",
    "    return x / y\n",
    "\n",
    "def ConfusionMatrix(y_true,y_predict):\n",
    "    CM=confusion_matrix(y_true, y_pred)\n",
    "    return CM\n",
    "\n",
    "# Multiclass Confusion Matrix\n",
    "# Entries:\n",
    "# y_true: true values of the classification\n",
    "# y_predict: predict values of the classification\n",
    "# C: quantity of classes \n",
    "\n",
    "# Haciendo la matriz de confusion binaria para la clase i\n",
    "def MultiClassConfusionMatrix(y_true,y_pred):\n",
    "    \n",
    "    C= np.unique(y_true)\n",
    "    D=len(C)\n",
    "    \n",
    "    # Matriz de confusion general \n",
    "    CM=confusion_matrix(y_true, y_pred)\n",
    "    #print('###### General Confusion Matrix #####')\n",
    "    #print(CM)\n",
    "        \n",
    "    accuracy=np.zeros(D)\n",
    "    precision=np.zeros(D)\n",
    "    recall=np.zeros(D)\n",
    "    specificity=np.zeros(D)\n",
    "    clase = []#np.zeros(D, dtype = int)\n",
    "    \n",
    "    \n",
    "    for i in range(D):\n",
    "        #atrib=np.array(C)\n",
    "        #print('aquiii')\n",
    "        #print(C)\n",
    "        atributo=C[i]\n",
    "        row_i=CM[i,:]\n",
    "        col_i=CM[:,i]\n",
    "        \n",
    "        row_i_without_i=np.delete(row_i,i,0)\n",
    "        #print(row_i_without_i)\n",
    "        col_i_without_i=np.delete(col_i,i,0)\n",
    "        del_row_i=np.delete(CM,i,0)\n",
    "        del_col_i=np.delete(del_row_i,i,1)\n",
    "        \n",
    "        VP=CM[i,i]\n",
    "        #print(VP)\n",
    "        FN=np.sum(row_i_without_i)\n",
    "        #print(VN)\n",
    "        FP=np.sum(col_i_without_i)\n",
    "        VN=np.sum(del_col_i)\n",
    "#         print('VP VN FP FN', VP, VN,FP,FN )\n",
    "        \n",
    "        CM_new=[[VP,FN],[FP,VN]]\n",
    "        #print(CM_new)\n",
    "        CM_new=np.array(CM_new) # casting\n",
    "\n",
    "        # calculando las medidas de desempenho\n",
    "        div1=VP+VN+FP+FN\n",
    "        #print(div1)\n",
    "        div2=VP+FP\n",
    "        div3=VP+FN\n",
    "        div4=VN+FP\n",
    "        \n",
    "        accuracy[i]=save_value((VP+VN),div1)\n",
    "        precision[i]=save_value(VP,div2)\n",
    "        recall[i]=save_value(VP,div3)\n",
    "        specificity[i]=save_value(VN,div4)        \n",
    "        clase.append(atributo)\n",
    "        \n",
    "        \n",
    "        #print('###### Confusion Matrix para clase ',atributo, ' #####')\n",
    "        #print(CM_new)    \n",
    "        \n",
    "    Table = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'specificity': specificity, 'clase': clase}\n",
    "    df = pd.DataFrame(data=Table)\n",
    "    print(df)\n",
    "    aux = df.sum(axis = 0, skipna = True)\n",
    "    #print('df.shape')\n",
    "    #print(df.shape[0])\n",
    "    mean = aux[0] / df.shape[0]\n",
    "    print('   mean accuracy: ', mean)\n",
    "    #print(accuracy.shape)\n",
    "#     return accuracy\n",
    "    #print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>1.51590</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.52</td>\n",
       "      <td>1.90</td>\n",
       "      <td>72.86</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>1.51813</td>\n",
       "      <td>13.43</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1.18</td>\n",
       "      <td>72.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>123</td>\n",
       "      <td>1.51687</td>\n",
       "      <td>13.23</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.48</td>\n",
       "      <td>72.84</td>\n",
       "      <td>0.56</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.51750</td>\n",
       "      <td>12.82</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.49</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>1.51596</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1.54</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>204</td>\n",
       "      <td>1.51658</td>\n",
       "      <td>14.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>1.51841</td>\n",
       "      <td>13.02</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.06</td>\n",
       "      <td>72.34</td>\n",
       "      <td>0.64</td>\n",
       "      <td>9.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>125</td>\n",
       "      <td>1.52177</td>\n",
       "      <td>13.20</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.15</td>\n",
       "      <td>72.75</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>171</td>\n",
       "      <td>1.52369</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>72.22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>12.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>1.51631</td>\n",
       "      <td>13.34</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.57</td>\n",
       "      <td>72.87</td>\n",
       "      <td>0.61</td>\n",
       "      <td>7.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>170</td>\n",
       "      <td>1.51994</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>73.03</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>175</td>\n",
       "      <td>1.52058</td>\n",
       "      <td>12.85</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.17</td>\n",
       "      <td>72.18</td>\n",
       "      <td>0.76</td>\n",
       "      <td>9.70</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1      2     3     4      5     6      7     8     9   10\n",
       "79    80  1.51590  12.82  3.52  1.90  72.86  0.69   7.97  0.00  0.00   2\n",
       "0      1  1.52101  13.64  4.49  1.10  71.78  0.06   8.75  0.00  0.00   1\n",
       "132  133  1.51813  13.43  3.98  1.18  72.49  0.58   8.15  0.00  0.00   2\n",
       "122  123  1.51687  13.23  3.54  1.48  72.84  0.56   8.10  0.00  0.00   2\n",
       "20    21  1.51750  12.82  3.55  1.49  72.75  0.54   8.52  0.00  0.19   1\n",
       "74    75  1.51596  13.02  3.56  1.54  73.11  0.72   7.90  0.00  0.00   2\n",
       "203  204  1.51658  14.80  0.00  1.99  73.11  0.00   8.28  1.71  0.00   7\n",
       "96    97  1.51841  13.02  3.62  1.06  72.34  0.64   9.13  0.00  0.15   2\n",
       "124  125  1.52177  13.20  3.68  1.15  72.75  0.54   8.52  0.00  0.00   2\n",
       "212  213  1.51651  14.38  0.00  1.94  73.61  0.00   8.48  1.57  0.00   7\n",
       "170  171  1.52369  13.44  0.00  1.58  72.22  0.32  12.24  0.00  0.00   5\n",
       "73    74  1.51631  13.34  3.57  1.57  72.87  0.61   7.89  0.00  0.00   2\n",
       "169  170  1.51994  13.27  0.00  1.76  73.03  0.47  11.32  0.00  0.00   5\n",
       "174  175  1.52058  12.85  1.61  2.17  72.18  0.76   9.70  0.24  0.51   5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randomForest(n_times = 10, dataset=None):\n",
    "    for i in range(n_times):\n",
    "        numbers_elements = math.floor(math.sqrt(dataset.shape[0]))\n",
    "        #print('numbers_elements')\n",
    "        #print(numbers_elements)\n",
    "        #print('dataset.shape[0]')\n",
    "        #print(dataset.shape[0])\n",
    "        # Generate sampling\n",
    "        return dataset.loc[np.random.choice(dataset.index, numbers_elements, replace=False)]\n",
    "        #dataset.head\n",
    "glass = pd.read_csv('glass.data', header = None)\n",
    "n_glass = glass.iloc\n",
    "d = randomForest(1, glass)\n",
    "d.head(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_glass\n",
      "y_glass\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Iris-setosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1139208a41a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mr_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mr_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcurrent_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p37/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p37/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/envs/p37/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Iris-setosa'"
     ]
    }
   ],
   "source": [
    "#GLASS DATASET\n",
    "\n",
    "#glass = pd.read_csv('glass.data')\n",
    "#glass_data = glass.values\n",
    "#y_glass = glass_data[:, 10]\n",
    "#x_glass = glass_data[:, 1:10]\n",
    "\n",
    "\n",
    "# Iris DATASET\n",
    "glass = pd.read_csv('bezdekIris.data')\n",
    "glass_data = glass.values\n",
    "y_glass = glass_data[:, 4]\n",
    "x_glass = glass_data[:, 0:4]\n",
    "\n",
    "# Porto Dataset\n",
    "#glass = pd.read_csv('train.csv')\n",
    "#aux = glass.shape[1]\n",
    "#x_glass = glass.values[:, 2:aux] \n",
    "#y_glass = glass.values[:, 1]\n",
    "\n",
    "print('x_glass')\n",
    "print('y_glass')\n",
    "\n",
    "\n",
    "best_accuracy_f = 0\n",
    "best_pred_f     = []\n",
    "best_target_f   = []\n",
    "\n",
    "best_accuracy_t = 0\n",
    "best_pred_t     = []\n",
    "best_target_t   = []\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(x_glass):\n",
    "    #x_train, x_test = x_glass.iloc[train_index], x_glass.iloc[test_index]\n",
    "    #y_train, y_test = y_glass.iloc[train_index], y_glass.iloc[test_index]\n",
    "    \n",
    "    x_train, x_test = x_glass[train_index], x_glass[test_index]\n",
    "    y_train, y_test = y_glass[train_index], y_glass[test_index]\n",
    "    \n",
    "    r_clf = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "    r_clf.fit(x_train, y_train)\n",
    "    y_pred = r_clf.predict(x_test)\n",
    "    current_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if current_accuracy > best_accuracy_f:\n",
    "        best_accuracy_f = current_accuracy\n",
    "        best_pred_f     = y_pred\n",
    "        best_target_f   = y_test\n",
    "    \n",
    "    \n",
    "    t_clf = DecisionTreeClassifier(criterion = 'gini')\n",
    "    t_clf.fit(x_train, y_train)\n",
    "    y_pred_t = t_clf.predict(x_test)        \n",
    "    current_accuracy_t = accuracy_score(y_test, y_pred_t)\n",
    "    \n",
    "    if current_accuracy_t > best_accuracy_t:\n",
    "        best_accuracy_t = current_accuracy        \n",
    "        best_pred_t     = y_pred_t\n",
    "        best_target_t   = y_test\n",
    "\n",
    "        \n",
    "print('SALIDA RANDOM FOREST')\n",
    "MultiClassConfusionMatrix(best_target_f, best_pred_f)\n",
    "\n",
    "print('SALIDA ONLY TREE')\n",
    "MultiClassConfusionMatrix(best_target_t, best_pred_t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
